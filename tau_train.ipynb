{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec2530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TAU 모델 학습 스크립트\n",
    "기존 URP_baseline.ipynb 기반 - 바로 실행 가능\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import netCDF4 as nc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import *\n",
    "from tau_frost_model import get_tau_model\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718fe994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path name: results/asos_16ch_time[-18, -15, -12]_2km_TAU_early_fusion\n",
      "ASOS weight: 1.00, AAFOS weight: 0.00\n"
     ]
    }
   ],
   "source": [
    "# ====== 실험 설정 ====== #\n",
    "seeds = [1]  # 10번 실험\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # 입력 크기가 고정되면 속도 향상\n",
    "torch.backends.cudnn.deterministic = False  # 재현성보다 속도 우선\n",
    "\n",
    "# 데이터 설정\n",
    "ASOS = True\n",
    "AAFOS = False\n",
    "assert ASOS or AAFOS, \"At least one of ASOS or AAFOS must be True.\"\n",
    "\n",
    "channels = '16ch'\n",
    "time_range = [-18, -15, -12]  # TAU: 4개 시점 (baseline은 [-12])\n",
    "n_times = len(time_range)\n",
    "resolution = '2km'\n",
    "postfix = 'TAU_early_fusion'\n",
    "tau_n_heads = 8\n",
    "tau_n_layers = 2\n",
    "\n",
    "# 출력 경로\n",
    "output_path = \"results/\"\n",
    "output_path += 'asos_' if ASOS else ''\n",
    "output_path += 'aafos_' if AAFOS else ''\n",
    "output_path += channels + '_'\n",
    "output_path += 'time' + str(time_range) + '_'\n",
    "output_path += resolution\n",
    "output_path += ('_' + postfix) if postfix != '' else postfix\n",
    "print(f\"Output path name: {output_path}\")\n",
    "\n",
    "# ASOS:AAFOS 비율\n",
    "asos_aafos_ratio = 5.0\n",
    "asos_weight = asos_aafos_ratio / (asos_aafos_ratio + 1.0 * AAFOS) if ASOS else 0.0\n",
    "aafos_weight = 1.0 / (asos_aafos_ratio * ASOS + 1.0) if AAFOS else 0.0\n",
    "print(f\"ASOS weight: {asos_weight:.2f}, AAFOS weight: {aafos_weight:.2f}\")\n",
    "\n",
    "# 기타 설정\n",
    "latlon = False\n",
    "central_patch = False\n",
    "use_patch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04e0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 채널 설정 ====== #\n",
    "if channels == '16ch':\n",
    "    channels_name = ['vi004','vi005','vi006','vi008','nr013','nr016','sw038',\n",
    "                     'wv063','wv069','wv073','ir087','ir096','ir105','ir112','ir123','ir133']\n",
    "    channels_calib = ['vi004','vi005','vi006','vi008','nr013','nr016','sw038',\n",
    "                      'wv063','wv069','wv073','ir087','ir096','ir105','ir112','ir123','ir133']\n",
    "    \n",
    "    channels_mean = [1.1912e-01, 1.1464e-01, 1.0734e-01, 1.2504e-01, 5.4983e-02, 9.0381e-02,\n",
    "                     2.7813e+02, 2.3720e+02, 2.4464e+02, 2.5130e+02, 2.6948e+02, 2.4890e+02,\n",
    "                     2.7121e+02, 2.7071e+02, 2.6886e+02, 2.5737e+02]\n",
    "    channels_std = [0.1306, 0.1303, 0.1306, 0.1501, 0.0268, 0.0838, 15.8211, 6.1468,\n",
    "                    7.8054, 9.3251, 16.4265, 9.6150, 17.2518, 17.6064, 17.0090, 12.5026]\n",
    "else:\n",
    "    raise ValueError(\"Invalid channels.\")\n",
    "\n",
    "n_channels = len(channels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f26657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total channels: 51\n",
      "ASOS stations: [93, 108, 112, 119, 131, 133, 136, 143, 146, 156, 177, 102, 104, 115, 138, 152, 155, 159, 165, 168, 169, 184, 189]\n"
     ]
    }
   ],
   "source": [
    "# ====== 데이터 설정 ====== #\n",
    "train_data_info_list = []\n",
    "if ASOS:\n",
    "    train_data_info_list.append({\n",
    "        'label_type': 'asos',\n",
    "        'start_date_str': '20200101',\n",
    "        'end_date_str': '20230630',\n",
    "        'hour_col_pairs': [(6, 'AM')],\n",
    "        'label_keys': ['93','108','112','119','131','133','136','143','146','156','177',\n",
    "                       '102','104','115','138','152','155','159','165','168','169','184','189']\n",
    "    })\n",
    "\n",
    "test_asos_data_info_list = [\n",
    "    {\n",
    "        'label_type': 'asos',\n",
    "        'start_date_str': '20230701',\n",
    "        'end_date_str': '20240630',\n",
    "        'hour_col_pairs': [(6, 'AM')],\n",
    "        'label_keys': ['93','108','112','119','131','133','136','143','146','156','177',\n",
    "                       '102','104','115','138','152','155','159','165','168','169','184','189']\n",
    "    },\n",
    "] if ASOS else None\n",
    "\n",
    "# 이미지 크기 설정\n",
    "origin_size = 900 if resolution == '2km' else 1800\n",
    "image_size = 512 if resolution == '2km' else 1024\n",
    "patch_size = 512\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dm4/repo/data/kma_data/date_kst_URP_384'\n",
    "\n",
    "misc_channels = {\n",
    "    'elevation': 'elevation_1km_3600.npy',\n",
    "    'vegetation': 'vegetation_1km_3600.npy',\n",
    "    'watermap': 'watermap_1km_avg_3600.npy'\n",
    "}\n",
    "lat_lon_path = 'assets/gk2a_ami_ko010lc_latlon.nc'\n",
    "\n",
    "# 학습 설정\n",
    "batch_size = 4\n",
    "num_workers = 8\n",
    "epochs = 25\n",
    "lr = 1e-3\n",
    "decay = [10, 20]\n",
    "lr_decay = 0.1\n",
    "weight_decay = 1e-5\n",
    "threshold = [0.25]\n",
    "\n",
    "# TAU 모델 설정\n",
    "fusion_type = 'early'  # 'early' or 'late'\n",
    "tau_n_heads = 8\n",
    "tau_n_layers = 2\n",
    "\n",
    "# ====== 자동 계산 값 ====== #\n",
    "asos_x_base, asos_y_base, asos_image_size = get_crop_base(image_size, label_type='asos')\n",
    "aafos_x_base, aafos_y_base, aafos_image_size = get_crop_base(image_size, label_type='aafos')\n",
    "aafos_x_base -= asos_x_base\n",
    "aafos_y_base -= asos_y_base\n",
    "\n",
    "total_channels = len(channels_name) * len(time_range) + len(misc_channels.keys())\n",
    "total_channels += 2 if latlon else 0\n",
    "print(f\"Total channels: {total_channels}\")\n",
    "\n",
    "# ====== 관측소 좌표 설정 ====== #\n",
    "asos_land_map = {k: coord_to_map(*v, origin_size) for k, v in ASOS_LAND_COORD.items()}\n",
    "asos_land_map = {k: (v[0] - asos_x_base, v[1] - asos_y_base) for k, v in asos_land_map.items()}\n",
    "asos_coast_map = {k: coord_to_map(*v, origin_size) for k, v in ASOS_COAST_COORD.items()}\n",
    "asos_coast_map = {k: (v[0] - asos_x_base, v[1] - asos_y_base) for k, v in asos_coast_map.items()}\n",
    "asos_map_dict = {**asos_land_map, **asos_coast_map}\n",
    "print(f\"ASOS stations: {list(asos_map_dict.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d771fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISC images shape: torch.Size([3, 512, 512])\n",
      "Total mean length: 51\n",
      "Total std length: 51\n"
     ]
    }
   ],
   "source": [
    "# ====== Mean/Std 설정 ====== #\n",
    "channels_mean = channels_mean * len(time_range)\n",
    "channels_std = channels_std * len(time_range)\n",
    "\n",
    "# ====== Misc Images 로드 ====== #\n",
    "misc_images = []\n",
    "for misc_channel, misc_path in misc_channels.items():\n",
    "    misc_image = np.load(f'assets/misc_channels/{misc_path}', allow_pickle=True)\n",
    "    misc_image = cv2.resize(misc_image, (asos_image_size, asos_image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    misc_images.append(misc_image)\n",
    "misc_images = np.stack(misc_images, axis=0)\n",
    "misc_images = torch.tensor(misc_images, dtype=torch.float32)\n",
    "\n",
    "if latlon:\n",
    "    lat_lon_data = nc.Dataset(lat_lon_path)\n",
    "    lat = lat_lon_data['lat'][:].data\n",
    "    lon = lat_lon_data['lon'][:].data\n",
    "    lat = cv2.resize(lat, (origin_size, origin_size), interpolation=cv2.INTER_CUBIC)\n",
    "    lon = cv2.resize(lon, (origin_size, origin_size), interpolation=cv2.INTER_CUBIC)\n",
    "    asos_lat = lat[asos_y_base:asos_y_base + asos_image_size, asos_x_base:asos_x_base + asos_image_size]\n",
    "    asos_lon = lon[asos_y_base:asos_y_base + asos_image_size, asos_x_base:asos_x_base + asos_image_size]\n",
    "    \n",
    "    lat_image = cv2.resize(asos_lat, (asos_image_size, asos_image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    lon_image = cv2.resize(asos_lon, (asos_image_size, asos_image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    lat_image = torch.tensor(lat_image, dtype=torch.float32).unsqueeze(0)\n",
    "    lon_image = torch.tensor(lon_image, dtype=torch.float32).unsqueeze(0)\n",
    "    misc_images = torch.cat([misc_images, lat_image, lon_image], dim=0)\n",
    "\n",
    "print(f'MISC images shape: {misc_images.shape}')\n",
    "\n",
    "# ====== n_misc 계산 ====== #\n",
    "n_misc = len(misc_channels) + (2 if latlon else 0)\n",
    "\n",
    "# Normalize misc\n",
    "misc_mean = misc_images.mean(dim=[1, 2], keepdim=True)\n",
    "misc_std = misc_images.std(dim=[1, 2], keepdim=True)\n",
    "\n",
    "total_mean = channels_mean + misc_mean.squeeze().tolist()\n",
    "total_std = channels_std + misc_std.squeeze().tolist()\n",
    "\n",
    "print(f'Total mean length: {len(total_mean)}')\n",
    "print(f'Total std length: {len(total_std)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037b46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOS patch candidates shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# ====== Patch Candidates 생성 ====== #\n",
    "asos_patch_candidate = np.zeros([image_size, image_size], dtype=np.uint8)\n",
    "for x, y in asos_map_dict.values():\n",
    "    y_min = np.clip(y - 3 * patch_size // 4, 0, image_size - patch_size + 1)\n",
    "    y_max = np.clip(y - patch_size // 4, 0, image_size - patch_size + 1)\n",
    "    x_min = np.clip(x - 3 * patch_size // 4, 0, image_size - patch_size + 1)\n",
    "    x_max = np.clip(x - patch_size // 4, 0, image_size - patch_size + 1)\n",
    "    asos_patch_candidate[y_min:y_max, x_min:x_max] = 1\n",
    "\n",
    "asos_patch_candidate = np.argwhere(asos_patch_candidate == 1)[:, [1, 0]]\n",
    "print(f'ASOS patch candidates shape: {asos_patch_candidate.shape}')\n",
    "\n",
    "patch_candidates = {'asos': asos_patch_candidate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ba4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Transform 설정 ====== #\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=total_mean, std=total_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884110c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_measure_valid(Y_test, Y_test_hat, cutoff=0.5):\n",
    "    Y_test = Y_test.ravel()\n",
    "    Y_test_hat = Y_test_hat.ravel()\n",
    "    \n",
    "    Y_valid = (~np.isnan(Y_test))\n",
    "    Y_test = Y_test[Y_valid]\n",
    "    Y_test_hat = Y_test_hat[Y_valid]\n",
    "\n",
    "    cfmat = confusion_matrix(Y_test, Y_test_hat > cutoff, labels = [0,1])\n",
    "    acc = np.trace(cfmat) / np.sum(cfmat)\n",
    "    csi = cfmat[1,1] /(np.sum(cfmat) - cfmat[0,0] + 1e-8)\n",
    "    \n",
    "    try:\n",
    "        auroc = roc_auc_score(Y_test, Y_test_hat)\n",
    "    except Exception as e:\n",
    "        auroc = 0.0\n",
    "\n",
    "    return csi, acc, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41aed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== TAU용 train 함수 (baseline 손실함수 유지) ====== #\n",
    "def train(model, images, labels, coords, map_dict, cls_num=0):\n",
    "    \"\"\"\n",
    "    TAU 모델용 학습 함수 - baseline과 동일한 손실함수 사용\n",
    "    \n",
    "    Args:\n",
    "        model: TAUDeepLab 모델\n",
    "        images: (B, T*C + misc, H, W) 입력 이미지 (이미 cuda로 이동됨)\n",
    "        labels: (B, N_stations) 관측소별 라벨\n",
    "        coords: (B, 2) 패치 좌표 [px, py]\n",
    "        map_dict: {station_id: (x, y)} 관측소 좌표\n",
    "        cls_num: 클래스 인덱스 (ASOS=0, AAFOS=1)\n",
    "    \n",
    "    Returns:\n",
    "        loss: Focal Loss + Non-frost Loss + CSI Loss\n",
    "    \"\"\"\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    # TAU 모델 forward - 입력 형태: (B, T*C + misc, H, W)\n",
    "    pred_map = model.forward(images)[:, cls_num]  # (B, H, W)\n",
    "    \n",
    "    # 관측소 위치에서 prediction 추출 (패치 좌표 고려)\n",
    "    pred_vec = torch.zeros_like(labels)\n",
    "    for b, (px, py) in enumerate(coords):\n",
    "        px, py = int(px), int(py)\n",
    "        for i, (x, y) in enumerate(map_dict.values()):\n",
    "            # 패치 내부에 있는 관측소만 prediction 사용\n",
    "            if px <= x < px + patch_size and py <= y < py + patch_size:\n",
    "                pred_vec[b, i] = pred_map[b, y - py, x - px]\n",
    "            else:\n",
    "                # 패치 외부 관측소는 라벨 값으로 대체 (loss 기여 없음)\n",
    "                pred_vec[b, i] = labels[b, i]\n",
    "    \n",
    "    # Valid mask (NaN 제외)\n",
    "    labels_valid = (~torch.isnan(labels)).float()\n",
    "    labels = torch.nan_to_num(labels, 0.0)\n",
    "    \n",
    "    # 1. Focal Loss\n",
    "    loss_focal_raw = sigmoid_focal_loss(pred_vec, labels, alpha=-1, gamma=2, reduction='none')\n",
    "    loss_focal = (loss_focal_raw * labels_valid).sum() / labels_valid.sum().clamp(min=1.0)\n",
    "    \n",
    "    # 2. Non-frost Loss (배치 내 모든 라벨이 0일 때 전체 맵에 대해 BCE 적용)\n",
    "    valid_any_batch = (labels_valid.sum() > 0)\n",
    "    all_zero_batch = ((labels * labels_valid).sum() == 0)\n",
    "    \n",
    "    if not (valid_any_batch and all_zero_batch):\n",
    "        loss_non_frost = torch.tensor(0.0, device=labels.device)\n",
    "    else:\n",
    "        loss_non_frost = binary_cross_entropy_with_logits(\n",
    "            pred_map, torch.zeros_like(pred_map), reduction='mean'\n",
    "        )\n",
    "    \n",
    "    # 3. CSI Loss (미분 가능한 CSI 근사)\n",
    "    pred_prob = torch.sigmoid(pred_vec)\n",
    "    tp = torch.sum(pred_prob * labels * labels_valid, dim=0)\n",
    "    fn = torch.sum((1 - pred_prob) * labels * labels_valid, dim=0)\n",
    "    fp = torch.sum(pred_prob * (1 - labels) * labels_valid, dim=0)\n",
    "    \n",
    "    # CSI = TP / (TP + FN + FP) → -log(CSI) 최소화\n",
    "    loss_csi = torch.mean(-torch.log(tp + 1e-10) + torch.log(tp + fn + fp + 1e-10))\n",
    "    \n",
    "    return loss_focal + loss_non_frost + loss_csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54efded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TAU Frost Forecasting Model Training\n",
      "============================================================\n",
      "Fusion type: early\n",
      "Time range: [-18, -15, -12]\n",
      "N times: 3, N channels: 16\n",
      "============================================================\n",
      "\n",
      "Creating datasets...\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:   1%|▌                                          | 17/1277 [00:00<00:07, 162.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20200101 AM skipped, 2019-12-31 12:00:00 not in date_table\n",
      "  - 20200104 AM skipped, 2020-01-03 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:  51%|█████████████████████▌                    | 656/1277 [00:02<00:01, 459.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20211003 AM skipped, 2021-10-02 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|█████████████████████████████████████████| 1277/1277 [00:04<00:00, 259.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 1274 image-label pairs prepared\n",
      "  - train_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 1274\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|███████████████████████████████████████████| 366/366 [00:01<00:00, 262.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 366 image-label pairs prepared\n",
      "  - test_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 366\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Seed 1\n",
      "============================================================\n",
      "모델 파라미터 수: 12,305,490\n",
      "== asos dataset length synced to 1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  0:   0%|          | 0/318 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 23.57 GiB of which 502.69 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 673.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 153\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ASOS:\n\u001b[32m    152\u001b[39m     images, label, coords = batch[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     loss_asos = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masos_map_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_num\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    155\u001b[39m     loss_asos = torch.tensor(\u001b[32m0.0\u001b[39m).cuda()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, images, labels, coords, map_dict, cls_num)\u001b[39m\n\u001b[32m     18\u001b[39m labels = labels.cuda()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# TAU 모델 forward - 입력 형태: (B, T*C + misc, H, W)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m pred_map = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m[:, cls_num]  \u001b[38;5;66;03m# (B, H, W)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 관측소 위치에서 prediction 추출 (패치 좌표 고려)\u001b[39;00m\n\u001b[32m     24\u001b[39m pred_vec = torch.zeros_like(labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/URP/tau_frost_model.py:305\u001b[39m, in \u001b[36mTAUDeepLab.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[33;03m    x: (B, T*C + C_misc, H, W) - baseline과 동일\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[33;03m    (B, num_classes, H, W)\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# TAU fusion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m x_fused = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtau_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, C + C_misc, H, W)\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Backbone\u001b[39;00m\n\u001b[32m    308\u001b[39m output = \u001b[38;5;28mself\u001b[39m.backbone(x_fused)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/URP/tau_frost_model.py:196\u001b[39m, in \u001b[36mTAUFusionEarly.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# 4. TAU blocks\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tau_blocks:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     x_flat, _ = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# 5. 마지막 시점의 feature 사용 (forecasting)\u001b[39;00m\n\u001b[32m    199\u001b[39m x_out = x_flat[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# (B*H*W, d_model)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/URP/tau_frost_model.py:115\u001b[39m, in \u001b[36mTAUBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    112\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x + attn_out)\n\u001b[32m    114\u001b[39m ffn_out = \u001b[38;5;28mself\u001b[39m.ffn(x)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, attn_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/modules/normalization.py:201\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/urp_env/lib/python3.11/site-packages/torch/nn/functional.py:2546\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2544\u001b[39m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight=weight, bias=bias, eps=eps\n\u001b[32m   2545\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 23.57 GiB of which 502.69 MiB is free. Including non-PyTorch memory, this process has 22.75 GiB memory in use. Of the allocated memory 21.78 GiB is allocated by PyTorch, and 673.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# ====== 메인 학습 루프 ====== #\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TAU Frost Forecasting Model Training\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Fusion type: {fusion_type}\")\n",
    "    print(f\"Time range: {time_range}\")\n",
    "    print(f\"N times: {n_times}, N channels: {n_channels}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # ====== 데이터셋 생성 ====== #\n",
    "    print(\"Creating datasets...\")\n",
    "    train_dataset = GK2ADataset(\n",
    "        data_path=data_path,\n",
    "        output_path=output_path,\n",
    "        data_info_list=train_data_info_list,\n",
    "        channels=channels,\n",
    "        time_range=time_range,\n",
    "        channels_calib=channels_calib,\n",
    "        image_size=image_size,\n",
    "        misc_images=misc_images,\n",
    "        patch_size=patch_size,\n",
    "        patch_candidates=patch_candidates,\n",
    "        transform=transform,\n",
    "        train=True\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=True  # GPU 전송 속도 향상\n",
    "    )\n",
    "    \n",
    "    if ASOS:\n",
    "        test_asos_dataset = GK2ADataset(\n",
    "            data_path=data_path,\n",
    "            output_path=output_path,\n",
    "            data_info_list=test_asos_data_info_list,\n",
    "            channels=channels,\n",
    "            time_range=time_range,\n",
    "            channels_calib=channels_calib,\n",
    "            image_size=image_size,\n",
    "            misc_images=misc_images,\n",
    "            patch_size=patch_size,\n",
    "            patch_candidates=None,\n",
    "            transform=transform,\n",
    "            train=False\n",
    "        )\n",
    "        test_asos_dataloader = DataLoader(\n",
    "            test_asos_dataset,\n",
    "            batch_size=batch_size // 2,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    # ====== Seed 별 학습 ====== #\n",
    "    for seed in seeds:\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'Seed {seed}')\n",
    "        print(f'{\"=\"*60}')\n",
    "        \n",
    "        if os.path.exists(f'{output_path}/{seed}/ckpt.pt'):\n",
    "            print(f'Seed {seed} already done. Skipping...')\n",
    "            continue\n",
    "        \n",
    "        # 시드 설정\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # TAU 모델 생성\n",
    "        model = get_tau_model(\n",
    "            total_channels=total_channels,\n",
    "            patch_size=patch_size,\n",
    "            n_channels=n_channels,\n",
    "            n_misc=n_misc,\n",
    "            n_times=n_times,\n",
    "            num_classes=2,\n",
    "            tau_n_heads=tau_n_heads,\n",
    "            tau_n_layers=tau_n_layers\n",
    "        )\n",
    "        model = model.cuda()\n",
    "\n",
    "        print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay, gamma=lr_decay)\n",
    "        \n",
    "        # AMP GradScaler 초기화\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        start_epoch = 0\n",
    "        \n",
    "        # 결과 저장\n",
    "        results = dict(\n",
    "            loss={'asos': [], 'aafos': [], 'total': []},\n",
    "            csi={'asos': {}, 'aafos': {}},\n",
    "            acc={'asos': {}, 'aafos': {}},\n",
    "            auroc={'asos': [], 'aafos': []},\n",
    "            best_asos={},\n",
    "            best_aafos={},\n",
    "            best_mean={},\n",
    "        )\n",
    "        \n",
    "        for cutoff in threshold:\n",
    "            cutoff_str = str(cutoff)\n",
    "            results['csi']['asos'][cutoff_str] = []\n",
    "            results['acc']['asos'][cutoff_str] = []\n",
    "            results['best_asos'][cutoff_str] = {'csi': 0.0, 'epoch': -1, 'model': None}\n",
    "            \n",
    "            results['csi']['aafos'][cutoff_str] = []\n",
    "            results['acc']['aafos'][cutoff_str] = []\n",
    "            results['best_aafos'][cutoff_str] = {'csi': 0.0, 'epoch': -1, 'model': None}\n",
    "            \n",
    "            results['best_mean'][cutoff_str] = {'csi': 0.0, 'epoch': -1, 'model': None}\n",
    "        \n",
    "        # Resume 체크\n",
    "        if os.path.exists(f'{output_path}/{seed}/resume.pt'):\n",
    "            resume = torch.load(f'{output_path}/{seed}/resume.pt')\n",
    "            model.load_state_dict(resume['model'])\n",
    "            optimizer.load_state_dict(resume['optimizer'])\n",
    "            scheduler.load_state_dict(resume['scheduler'])\n",
    "            if 'scaler' in resume:\n",
    "                scaler.load_state_dict(resume['scaler'])\n",
    "            start_epoch = resume['epoch'] + 1\n",
    "            results = resume['results']\n",
    "            print(f'Resuming from epoch {start_epoch}...')\n",
    "        \n",
    "        # ====== 학습 루프 ====== #\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            model.train()\n",
    "            \n",
    "            total_loss_asos = 0.0\n",
    "            total_loss_aafos = 0.0\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            # 데이터셋 길이 동기화\n",
    "            train_dataset.sync_dataset_length()\n",
    "            \n",
    "            pbar = tqdm(train_dataloader, desc=f'Epoch {epoch:2d}')\n",
    "            for batch in pbar:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "                # AMP autocast 적용\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # ASOS 학습\n",
    "                    if ASOS:\n",
    "                        images, label, coords = batch[0]\n",
    "                        loss_asos = train(model, images, label, coords, asos_map_dict, cls_num=0)\n",
    "                    else:\n",
    "                        loss_asos = torch.tensor(0.0).cuda()\n",
    "                    \n",
    "                    # AAFOS 학습\n",
    "                    if AAFOS:\n",
    "                        images, label, coords = batch[1] if ASOS else batch[0]\n",
    "                        loss_aafos = train(model, images, label, coords, aafos_map_dict, cls_num=1)\n",
    "                    else:\n",
    "                        loss_aafos = torch.tensor(0.0).cuda()\n",
    "                    \n",
    "                    loss = asos_weight * loss_asos + aafos_weight * loss_aafos\n",
    "                \n",
    "                # Scaler를 사용한 backward 및 optimizer step\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                total_loss_asos += loss_asos.item()\n",
    "                total_loss_aafos += loss_aafos.item()\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Progress bar 업데이트\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'asos': f'{loss_asos.item():.4f}'\n",
    "                })\n",
    "            \n",
    "            total_loss_asos /= len(train_dataloader)\n",
    "            total_loss_aafos /= len(train_dataloader)\n",
    "            total_loss /= len(train_dataloader)\n",
    "            \n",
    "            results['loss']['asos'].append(total_loss_asos)\n",
    "            results['loss']['aafos'].append(total_loss_aafos)\n",
    "            results['loss']['total'].append(total_loss)\n",
    "            \n",
    "            print(f'Epoch {epoch:2d} - Total: {total_loss:.4f}, ASOS: {total_loss_asos:.4f}, AAFOS: {total_loss_aafos:.4f}')\n",
    "            scheduler.step()\n",
    "            \n",
    "            # ====== 평가 ====== #\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if ASOS:\n",
    "                    asos_pred_vec_list = []\n",
    "                    asos_labels_list = []\n",
    "                    \n",
    "                    for batch in test_asos_dataloader:\n",
    "                        images, label, coords = batch[0]\n",
    "                        images = images.cuda()\n",
    "                        \n",
    "                        # 평가 시에도 AMP autocast 적용 (추론 속도 향상)\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            # forward_by_patch는 (B, T*C + misc, H, W) 형태를 받음\n",
    "                            pred_map = model.forward_by_patch(images, patch_size=patch_size)[:, 0]\n",
    "                            pred_map = F.sigmoid(pred_map)\n",
    "                        \n",
    "                        # 관측소 위치에서 prediction 추출\n",
    "                        pred_vec = []\n",
    "                        for x, y in asos_map_dict.values():\n",
    "                            pred_vec.append(pred_map[:, y, x])\n",
    "                        pred_vec = torch.stack(pred_vec, dim=1)\n",
    "                        \n",
    "                        asos_pred_vec_list.append(pred_vec.cpu().numpy())\n",
    "                        asos_labels_list.append(label.numpy())\n",
    "                    \n",
    "                    pred_vecs = np.concatenate(asos_pred_vec_list, axis=0)\n",
    "                    labels = np.concatenate(asos_labels_list, axis=0)\n",
    "                    \n",
    "                    for cutoff in threshold:\n",
    "                        asos_result = calc_measure_valid(labels, pred_vecs, cutoff=cutoff)\n",
    "                        csi, acc, auroc = asos_result[0], asos_result[1], asos_result[2]\n",
    "                        cutoff_str = str(cutoff)\n",
    "                        \n",
    "                        results['csi']['asos'][cutoff_str].append(csi)\n",
    "                        results['acc']['asos'][cutoff_str].append(acc)\n",
    "                        \n",
    "                        is_best = csi > results['best_asos'][cutoff_str]['csi']\n",
    "                        print(f'\\t - ASOS (T={cutoff:.2f}): CSI {csi:.4f}, AUROC {auroc:.4f} {\"*\" if is_best else \"\"}')\n",
    "                        \n",
    "                        if is_best:\n",
    "                            results['best_asos'][cutoff_str]['csi'] = csi\n",
    "                            results['best_asos'][cutoff_str]['epoch'] = epoch\n",
    "                            results['best_asos'][cutoff_str]['model'] = model.state_dict()\n",
    "                        \n",
    "                        # Land/Coast 분리 평가\n",
    "                        asos_land_result = calc_measure_valid(labels[:, :11], pred_vecs[:, :11], cutoff=cutoff)\n",
    "                        asos_coast_result = calc_measure_valid(labels[:, 11:], pred_vecs[:, 11:], cutoff=cutoff)\n",
    "                        print(f'\\t   - Land:  CSI {asos_land_result[0]:.4f}, AUROC {asos_land_result[2]:.4f}')\n",
    "                        print(f'\\t   - Coast: CSI {asos_coast_result[0]:.4f}, AUROC {asos_coast_result[2]:.4f}')\n",
    "                    \n",
    "                    results['auroc']['asos'].append(auroc)\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            # Resume 저장 (scaler 상태 포함)\n",
    "            resume = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'scaler': scaler.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'results': results\n",
    "            }\n",
    "            os.makedirs(f'{output_path}/{seed}', exist_ok=True)\n",
    "            torch.save(resume, f'{output_path}/{seed}/resume.pt')\n",
    "        \n",
    "        # 최종 저장\n",
    "        torch.save(results, f'{output_path}/{seed}/ckpt.pt')\n",
    "        if os.path.exists(f'{output_path}/{seed}/resume.pt'):\n",
    "            os.remove(f'{output_path}/{seed}/resume.pt')\n",
    "        \n",
    "        print(f'\\nSeed {seed} completed!')\n",
    "        print(f'Best ASOS CSI (T=0.25): {results[\"best_asos\"][\"0.25\"][\"csi\"]:.4f} at epoch {results[\"best_asos\"][\"0.25\"][\"epoch\"]}')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"All seeds completed!\")\n",
    "    print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
