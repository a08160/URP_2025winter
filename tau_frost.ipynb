{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Temporal Attention Unit (TAU) for Frost Prediction\n",
    "\n",
    "**Paper**: \"Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning\" (CVPR 2023)\n",
    "\n",
    "논문 구조 그대로 구현:\n",
    "1. Spatial Encoder: 단순 2D CNN\n",
    "2. Temporal Module: TAU 블록 스택\n",
    "   - Intra-frame Statical Attention (SA)\n",
    "   - Inter-frame Dynamical Attention (DA)\n",
    "3. Spatial Decoder: 단순 2D CNN with skip connection\n",
    "4. Loss: MSE + α * DDR (Differential Divergence Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import netCDF4 as nc\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *\n",
    "from utils.gk2a_dataset import GK2ADataset\n",
    "from utils.projection import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.frost_tau import FrostTAU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 1. 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "# ====== 실험 설정 ======\nseeds = [0, 1, 2]\n\n# 데이터 설정\nASOS = True\nAAFOS = False\n\nchannels = '16ch'\ntime_range = [-18, -15, -12]  # 3개 시점\nresolution = '2km'\npostfix = 'tau'  # TAU 모델 사용\n\n# === Window 설정 (met2net과 동일한 방식) ===\n# 논문대로 구현: window_size=1, window_stride=1 (각 프레임을 독립적으로 처리)\n# 기존 방식: window_size=None (전체 시퀀스를 한번에 처리)\nwindow_size = 1      # 각 윈도우에 포함되는 타임스텝 수 (None이면 seq_len)\nwindow_stride = 1    # 윈도우 간 이동 거리\n\noutput_path = \"results/\"\noutput_path += 'asos_' if ASOS else ''\noutput_path += 'aafos_' if AAFOS else ''\noutput_path += channels + '_'\noutput_path += 'time' + str(time_range) + '_'\noutput_path += resolution\noutput_path += ('_' + postfix) if postfix else ''\noutput_path += f'_ws{window_size}_stride{window_stride}'  # window 설정 추가\nprint(f\"Output path: {output_path}\")\n\n# ASOS/AAFOS 가중치\nasos_aafos_ratio = 5.0\nasos_weight = asos_aafos_ratio / (asos_aafos_ratio + 1.0 * AAFOS) if ASOS else 0.0\naafos_weight = 1.0 / (asos_aafos_ratio * ASOS + 1.0) if AAFOS else 0.0\nprint(f\"ASOS weight: {asos_weight:.2f}, AAFOS weight: {aafos_weight:.2f}\")\n\n# 채널 설정\nchannels_name = ['vi004','vi005','vi006','vi008','nr013','nr016','sw038','wv063','wv069','wv073','ir087','ir096','ir105','ir112','ir123','ir133']\nchannels_calib = channels_name.copy()\n\nchannels_mean = [1.1912e-01, 1.1464e-01, 1.0734e-01, 1.2504e-01, 5.4983e-02, 9.0381e-02,\n            2.7813e+02, 2.3720e+02, 2.4464e+02, 2.5130e+02, 2.6948e+02, 2.4890e+02,\n            2.7121e+02, 2.7071e+02, 2.6886e+02, 2.5737e+02]\nchannels_std = [0.1306,  0.1303,  0.1306,  0.1501,  0.0268,  0.0838, 15.8211,  6.1468,\n            7.8054,  9.3251, 16.4265,  9.6150, 17.2518, 17.6064, 17.0090, 12.5026]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 정보\ntrain_data_info_list = [{\n    'label_type': 'asos',\n    'start_date_str': '20200101',\n    'end_date_str': '20230630',\n    'hour_col_pairs': [(6,'AM')],\n    'label_keys': ['93','108','112','119','131','133','136','143','146','156','177','102','104','115','138','152','155','159','165','168','169','184','189']\n}] if ASOS else None\n\ntest_asos_data_info_list = [{\n    'label_type': 'asos',\n    'start_date_str': '20230701',\n    'end_date_str': '20240630',\n    'hour_col_pairs': [(6,'AM')],\n    'label_keys': ['93','108','112','119','131','133','136','143','146','156','177','102','104','115','138','152','155','159','165','168','169','184','189']\n}] if ASOS else None\n\n# 이미지 설정\norigin_size = 900 if resolution == '2km' else 1800\nimage_size = 192\npatch_size = 192\n\n# 데이터 경로\ndata_path = '/home/work/js/repo/data/kma_data/date_kst'\nlat_lon_path = 'assets/gk2a_ami_ko010lc_latlon.nc'\n\nmisc_channels = {\n    'elevation':'elevation_1km_3600.npy',\n    'vegetation':'vegetation_1km_3600.npy',\n    'watermap':'watermap_1km_avg_3600.npy'\n}\n\n# 학습 설정\nbatch_size = 16\nnum_workers = 8\nepochs = 25\nlr = 1e-3\ndecay = [10, 20]\nlr_decay = 0.1\nweight_decay = 1e-5\nthreshold = [0.25]\n\n# 관측소 좌표\nasos_x_base, asos_y_base, asos_image_size = get_crop_base(image_size, label_type='asos')\nseq_len = len(time_range)\ntotal_channels = len(channels_name) + len(misc_channels.keys())\n\n# 윈도우 설정 출력\nactual_window_size = window_size if window_size is not None else seq_len\nn_windows = (seq_len - actual_window_size) // window_stride + 1\n\nprint(f\"seq_len: {seq_len}\")\nprint(f\"total_channels: {total_channels}\")\nprint(f\"image_size: {image_size}\")\nprint(f\"\\nWindow config: size={actual_window_size}, stride={window_stride}\")\nprint(f\"Number of windows: {n_windows}\")\nprint(f\"Head input channels: {n_windows * actual_window_size * total_channels}\")"
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "station-map",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관측소 좌표\n",
    "asos_map_dict = get_station_map(image_size, label_type='asos', origin_size=origin_size)\n",
    "\n",
    "asos_land_keys = list(ASOS_LAND_COORD.keys())\n",
    "asos_coast_keys = list(ASOS_COAST_COORD.keys())\n",
    "asos_land_map = {k: v for k, v in asos_map_dict.items() if k in asos_land_keys}\n",
    "asos_coast_map = {k: v for k, v in asos_map_dict.items() if k in asos_coast_keys}\n",
    "\n",
    "print(f\"ASOS stations: {len(asos_map_dict)}\")\n",
    "print(f\"  - Land: {len(asos_land_map)}\")\n",
    "print(f\"  - Coast: {len(asos_coast_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "misc-images",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc 이미지 로드\n",
    "misc_images = []\n",
    "for misc_channel, misc_path in misc_channels.items():\n",
    "    misc_image = np.load(f'assets/misc_channels/{misc_path}', allow_pickle=True)\n",
    "    misc_image = process_misc_image(misc_image, image_size, interpolation='cubic')\n",
    "    misc_images.append(misc_image)\n",
    "\n",
    "misc_images = np.stack(misc_images, axis=0)\n",
    "misc_images = torch.tensor(misc_images, dtype=torch.float32)\n",
    "print(f\"MISC images shape: {misc_images.shape}\")\n",
    "\n",
    "# Normalize\n",
    "misc_mean = misc_images.mean(dim=[1,2], keepdim=True)\n",
    "misc_std = misc_images.std(dim=[1,2], keepdim=True)\n",
    "\n",
    "total_mean = channels_mean + misc_mean.squeeze().tolist()\n",
    "total_std = channels_std + misc_std.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patch-candidates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch candidates (192x192에서는 전체 이미지 사용)\n",
    "asos_patch_candidate = np.zeros([image_size, image_size], dtype=np.uint8)\n",
    "for x, y in asos_map_dict.values():\n",
    "    y_min = np.clip(y - 3*patch_size//4, 0, image_size - patch_size+1)\n",
    "    y_max = np.clip(y - patch_size//4, 0, image_size - patch_size+1)\n",
    "    x_min = np.clip(x - 3*patch_size//4, 0, image_size - patch_size+1)\n",
    "    x_max = np.clip(x - patch_size//4, 0, image_size - patch_size+1)\n",
    "    asos_patch_candidate[y_min:y_max, x_min:x_max] = 1\n",
    "\n",
    "asos_patch_candidate = np.argwhere(asos_patch_candidate == 1)[:, [1, 0]]\n",
    "patch_candidates = {'asos': asos_patch_candidate}\n",
    "print(f\"ASOS patch candidates: {asos_patch_candidate.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataloader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "class SequenceNormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32)\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        if tensor.dim() == 4:  # (T, C, H, W)\n",
    "            mean = self.mean.view(1, -1, 1, 1)\n",
    "            std = self.std.view(1, -1, 1, 1)\n",
    "        else:  # (C, H, W)\n",
    "            mean = self.mean.view(-1, 1, 1)\n",
    "            std = self.std.view(-1, 1, 1)\n",
    "        return (tensor - mean) / std\n",
    "\n",
    "transform = SequenceNormalize(mean=total_mean, std=total_std)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = GK2ADataset(\n",
    "    data_path=data_path, output_path=output_path, data_info_list=train_data_info_list,\n",
    "    channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "    image_size=image_size, misc_images=misc_images,\n",
    "    patch_size=patch_size, patch_candidates=patch_candidates,\n",
    "    transform=transform, train=True\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "if ASOS:\n",
    "    test_asos_dataset = GK2ADataset(\n",
    "        data_path=data_path, output_path=output_path, data_info_list=test_asos_data_info_list,\n",
    "        channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "        image_size=image_size, misc_images=misc_images,\n",
    "        patch_size=patch_size, patch_candidates=None,\n",
    "        transform=transform, train=False\n",
    "    )\n",
    "    test_asos_dataloader = DataLoader(test_asos_dataset, batch_size=batch_size//2, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. TAU 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-init",
   "metadata": {},
   "outputs": [],
   "source": "# TAU 모델 설정\nmodel = FrostTAU(\n    seq_len=seq_len,\n    in_channels=total_channels,\n    img_size=image_size,\n    out_channels=1,\n    hid_S=64,        # Encoder/Decoder hidden channels\n    N_S=4,           # Encoder/Decoder layers\n    N_T=8,           # TAU blocks\n    kernel_size=21,  # TAU attention kernel size\n    mlp_ratio=4.0,\n    drop=0.0,\n    drop_path=0.1,\n    # Window parameters\n    window_size=window_size,\n    window_stride=window_stride,\n).cuda()\n\n# 윈도우 설정 확인\nprint(f\"Window config: size={model.window_size}, stride={model.window_stride}\")\nprint(f\"Number of windows: {model.n_windows}\")\n\n# Parameter count\nn_params = sum(p.numel() for p in model.parameters())\nn_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total parameters: {n_params:,}\")\nprint(f\"Trainable parameters: {n_trainable:,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 4. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def calc_measure_valid(Y_test, Y_test_hat, cutoff=0.5):\n",
    "    Y_test = Y_test.ravel()\n",
    "    Y_test_hat = Y_test_hat.ravel()\n",
    "    \n",
    "    Y_valid = (~np.isnan(Y_test))\n",
    "    Y_test = Y_test[Y_valid]\n",
    "    Y_test_hat = Y_test_hat[Y_valid]\n",
    "\n",
    "    cfmat = confusion_matrix(Y_test, Y_test_hat > cutoff, labels=[0,1])\n",
    "    acc = np.trace(cfmat) / np.sum(cfmat)\n",
    "    csi = cfmat[1,1] / (np.sum(cfmat) - cfmat[0,0] + 1e-8)\n",
    "    \n",
    "    try:\n",
    "        auroc = roc_auc_score(Y_test, Y_test_hat)\n",
    "    except:\n",
    "        auroc = 0.0\n",
    "\n",
    "    return csi, acc, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-step",
   "metadata": {},
   "outputs": [],
   "source": "def train_step(model, images, labels, coords, map_dict, cls_idx=0, lambda_tau=0.1):\n    \"\"\"TAU 학습 스텝 (Sliding Window 지원)\"\"\"\n    images = images.cuda(non_blocking=True)\n    labels = labels.cuda(non_blocking=True)\n\n    y_target = images.clone()\n    pred_map, loss_dict = model(images, y_target)\n    pred_map = pred_map[:, cls_idx]\n\n    pred_vec = torch.zeros_like(labels)\n\n    for b, (px, py) in enumerate(coords):\n        for i, (x, y) in enumerate(map_dict.values()):\n            if px <= x < px + patch_size and py <= y < py + patch_size:\n                pred_vec[b, i] = pred_map[b, y - py, x - px]\n            else:\n                pred_vec[b, i] = labels[b, i]\n\n    labels_valid = (~torch.isnan(labels)).float()\n    labels = torch.nan_to_num(labels, 0.0)\n\n    # Focal loss\n    loss_focal_raw = sigmoid_focal_loss(pred_vec, labels, alpha=-1, gamma=2, reduction='none')\n    loss_focal = (loss_focal_raw * labels_valid).sum() / labels_valid.sum().clamp(min=1.0)\n\n    # Non-frost loss\n    valid_any_batch = (labels_valid.sum() > 0)\n    all_zero_batch = ((labels * labels_valid).sum() == 0)\n\n    if not (valid_any_batch and all_zero_batch):\n        loss_non_frost = torch.tensor(0.0, device=labels.device)\n    else:\n        loss_non_frost = binary_cross_entropy_with_logits(\n            pred_map, torch.zeros_like(pred_map), reduction='mean'\n        )\n\n    # CSI loss\n    prob = torch.sigmoid(pred_vec)\n    tp = torch.sum(prob * labels * labels_valid, dim=0)\n    fn = torch.sum((1 - prob) * labels * labels_valid, dim=0)\n    fp = torch.sum(prob * (1 - labels) * labels_valid, dim=0)\n    loss_csi = torch.mean(-torch.log(tp + 1e-10) + torch.log(tp + fn + fp + 1e-10))\n\n    # Total loss\n    loss_cls = loss_focal + loss_non_frost + loss_csi\n    \n    # TAU loss (MSE + DDR) - DDR은 window_size > 1일 때만 계산됨\n    loss_mse = loss_dict['loss_mse']\n    loss_ddr = loss_dict['loss_ddr']\n    loss_tau = loss_mse + loss_ddr\n    total_loss = loss_cls + lambda_tau * loss_tau\n\n    return total_loss, {\n        'cls': loss_cls.item(),\n        'mse': loss_mse.item() if torch.is_tensor(loss_mse) else loss_mse,\n        'ddr': loss_ddr.item() if torch.is_tensor(loss_ddr) else loss_ddr,\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-loop",
   "metadata": {},
   "outputs": [],
   "source": "# 학습 루프\nlambda_tau = 0.1\naccumulation_steps = 4\n\nprint(f\"Gradient Accumulation: {accumulation_steps} steps\")\nprint(f\"Mini-batch size: {batch_size}, Effective batch size: {batch_size * accumulation_steps}\")\nprint(f\"Window config: size={window_size}, stride={window_stride}\")\n\nfor seed in seeds:\n    if os.path.exists(f'{output_path}/{seed}/ckpt.pt'):\n        print(f'Seed {seed} already done. Skipping...')\n        continue\n\n    set_seed(seed)\n    os.makedirs(f'{output_path}/{seed}', exist_ok=True)\n\n    model = FrostTAU(\n        seq_len=seq_len,\n        in_channels=total_channels,\n        img_size=image_size,\n        out_channels=1,\n        hid_S=64,\n        N_S=4,\n        N_T=8,\n        kernel_size=21,\n        mlp_ratio=4.0,\n        drop=0.0,\n        drop_path=0.1,\n        # Window parameters\n        window_size=window_size,\n        window_stride=window_stride,\n    ).cuda()\n\n    print(f\"Model window_size={model.window_size}, n_windows={model.n_windows}\")\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay, gamma=lr_decay)\n\n    results = {\n        'loss': {'asos': [], 'total': []},\n        'csi': {'asos': {}},\n        'acc': {'asos': {}},\n        'auroc': {'asos': []},\n        'best_asos': {},\n    }\n\n    for cutoff_str in threshold:\n        cutoff_str = str(cutoff_str)\n        results['csi']['asos'][cutoff_str] = []\n        results['acc']['asos'][cutoff_str] = []\n        results['best_asos'][cutoff_str] = {'csi': 0.0, 'epoch': -1, 'model': None}\n\n    for epoch in range(epochs):\n        model.train()\n        \n        total_loss = 0.0\n        total_loss_cls = 0.0\n        total_loss_mse = 0.0\n        total_loss_ddr = 0.0\n\n        train_dataset.sync_dataset_length()\n        optimizer.zero_grad(set_to_none=True)\n\n        for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch}\")):\n            images, label, coords = batch[0]\n            loss, loss_breakdown = train_step(\n                model, images, label, coords, asos_map_dict,\n                cls_idx=0, lambda_tau=lambda_tau\n            )\n\n            loss = loss / accumulation_steps\n            loss.backward()\n\n            if (batch_idx + 1) % accumulation_steps == 0:\n                optimizer.step()\n                optimizer.zero_grad(set_to_none=True)\n\n            total_loss += float(loss.item()) * accumulation_steps\n            total_loss_cls += loss_breakdown['cls']\n            total_loss_mse += loss_breakdown['mse']\n            total_loss_ddr += loss_breakdown['ddr']\n\n        if (batch_idx + 1) % accumulation_steps != 0:\n            optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n        n_batches = len(train_dataloader)\n        total_loss /= n_batches\n        total_loss_cls /= n_batches\n        total_loss_mse /= n_batches\n        total_loss_ddr /= n_batches\n\n        print(f\"Epoch {epoch} - Total: {total_loss:.4f}\")\n        print(f\"  L_cls: {total_loss_cls:.4f}, L_mse: {total_loss_mse:.4f}, L_ddr: {total_loss_ddr:.4f}\")\n\n        results['loss']['total'].append(total_loss)\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            pred_vecs = []\n            labels_list = []\n            pred_vecs_land = []\n            labels_land = []\n            pred_vecs_coast = []\n            labels_coast = []\n\n            for batch in test_asos_dataloader:\n                images, label, coords = batch[0]\n                images = images.cuda(non_blocking=True)\n\n                pred_map = model(images)[:, 0]\n\n                for b, (px, py) in enumerate(coords):\n                    pred_vec = []\n                    label_vec = []\n                    pred_vec_land = []\n                    label_land = []\n                    pred_vec_coast = []\n                    label_coast = []\n\n                    for i, (key, (x, y)) in enumerate(asos_map_dict.items()):\n                        if px <= x < px + patch_size and py <= y < py + patch_size:\n                            pred_val = pred_map[b, y - py, x - px].item()\n                            label_val = label[b, i].item()\n\n                            pred_vec.append(pred_val)\n                            label_vec.append(label_val)\n\n                            if key in asos_land_keys:\n                                pred_vec_land.append(pred_val)\n                                label_land.append(label_val)\n                            elif key in asos_coast_keys:\n                                pred_vec_coast.append(pred_val)\n                                label_coast.append(label_val)\n\n                    if pred_vec:\n                        pred_vecs.append(pred_vec)\n                        labels_list.append(label_vec)\n                    if pred_vec_land:\n                        pred_vecs_land.append(pred_vec_land)\n                        labels_land.append(label_land)\n                    if pred_vec_coast:\n                        pred_vecs_coast.append(pred_vec_coast)\n                        labels_coast.append(label_coast)\n\n            pred_vecs = np.array([p for pv in pred_vecs for p in pv])\n            labels_list = np.array([l for lv in labels_list for l in lv])\n            pred_vecs_land = np.array([p for pv in pred_vecs_land for p in pv])\n            labels_land = np.array([l for lv in labels_land for l in lv])\n            pred_vecs_coast = np.array([p for pv in pred_vecs_coast for p in pv])\n            labels_coast = np.array([l for lv in labels_coast for l in lv])\n\n            for cutoff in threshold:\n                cutoff_str = str(cutoff)\n                csi, acc, auroc = calc_measure_valid(labels_list, pred_vecs, cutoff=cutoff)\n                results['csi']['asos'][cutoff_str].append(csi)\n                results['acc']['asos'][cutoff_str].append(acc)\n\n                csi_land, _, _ = calc_measure_valid(labels_land, pred_vecs_land, cutoff=cutoff)\n                csi_coast, _, _ = calc_measure_valid(labels_coast, pred_vecs_coast, cutoff=cutoff)\n\n                is_best = csi > results['best_asos'][cutoff_str]['csi']\n                results['auroc']['asos'].append(auroc)\n\n                if is_best:\n                    results['best_asos'][cutoff_str]['csi'] = csi\n                    results['best_asos'][cutoff_str]['epoch'] = epoch\n                    results['best_asos'][cutoff_str]['model'] = copy.deepcopy(model.state_dict())\n\n                print(f\"  ASOS (T={cutoff}): CSI {csi:.4f}, AUROC {auroc:.4f} {'*' if is_best else ''}\")\n                print(f\"    Land: {csi_land:.4f}, Coast: {csi_coast:.4f}\")\n\n        scheduler.step()\n\n        # Save checkpoint\n        torch.save({\n            'epoch': epoch,\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'scheduler': scheduler.state_dict(),\n            'results': results,\n            'window_size': window_size,\n            'window_stride': window_stride,\n        }, f'{output_path}/{seed}/resume.pt')\n\n    # Save best model\n    for cutoff_str in threshold:\n        cutoff_str = str(cutoff_str)\n        if results['best_asos'][cutoff_str]['model'] is not None:\n            torch.save({\n                'model': results['best_asos'][cutoff_str]['model'],\n                'epoch': results['best_asos'][cutoff_str]['epoch'],\n                'csi': results['best_asos'][cutoff_str]['csi'],\n                'window_size': window_size,\n                'window_stride': window_stride,\n            }, f'{output_path}/{seed}/ckpt.pt')\n            print(f\"Seed {seed} - Best CSI: {results['best_asos'][cutoff_str]['csi']:.4f}\")\n\n    if os.path.exists(f'{output_path}/{seed}/resume.pt'):\n        os.remove(f'{output_path}/{seed}/resume.pt')"
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": "N_LAND = 11\nN_COAST = 12\n\nresults_dict = {}\nfor cutoff in threshold:\n    results_dict[str(cutoff)] = {\n        'asos': {},\n        'asos_land': {},\n        'asos_coast': {},\n    }\n\nfor seed in seeds:\n    ckpt_path = f'{output_path}/{seed}/ckpt.pt'\n    if not os.path.exists(ckpt_path):\n        print(f'Seed {seed} not found. Skipping...')\n        continue\n    \n    ckpt = torch.load(ckpt_path)\n    print(f'--- Seed {seed}: epoch {ckpt[\"epoch\"]}, CSI {ckpt[\"csi\"]:.4f} ---')\n    \n    # 저장된 window 설정 로드 (없으면 기본값)\n    ckpt_window_size = ckpt.get('window_size', window_size)\n    ckpt_window_stride = ckpt.get('window_stride', window_stride)\n\n    model = FrostTAU(\n        seq_len=seq_len,\n        in_channels=total_channels,\n        img_size=image_size,\n        out_channels=1,\n        hid_S=64,\n        N_S=4,\n        N_T=8,\n        kernel_size=21,\n        mlp_ratio=4.0,\n        drop=0.0,\n        drop_path=0.1,\n        # Window parameters from checkpoint\n        window_size=ckpt_window_size,\n        window_stride=ckpt_window_stride,\n    ).cuda()\n    \n    model.load_state_dict(ckpt['model'])\n    model.eval()\n\n    for cutoff in threshold:\n        cutoff_str = str(cutoff)\n\n        with torch.no_grad():\n            asos_pred_vec_list = []\n            asos_labels_list = []\n\n            for batch in tqdm(test_asos_dataloader, desc=f\"Eval Seed {seed}\"):\n                images, label, coords = batch[0]\n                images = images.cuda()\n\n                pred_map = model(images)[:, 0]\n                pred_map = torch.sigmoid(pred_map)\n\n                pred_vec = []\n                for x, y in asos_map_dict.values():\n                    if 0 <= y < pred_map.shape[1] and 0 <= x < pred_map.shape[2]:\n                        pred_vec.append(pred_map[:, y, x])\n                    else:\n                        pred_vec.append(torch.zeros(pred_map.shape[0], device=pred_map.device))\n                pred_vec = torch.stack(pred_vec, dim=1)\n\n                asos_pred_vec_list.append(pred_vec.cpu().numpy())\n                asos_labels_list.append(label.numpy())\n\n            pred_vecs = np.concatenate(asos_pred_vec_list, axis=0)\n            labels = np.concatenate(asos_labels_list, axis=0)\n\n            pred_vecs_land = pred_vecs[:, :N_LAND]\n            pred_vecs_coast = pred_vecs[:, N_LAND:]\n            labels_land = labels[:, :N_LAND]\n            labels_coast = labels[:, N_LAND:]\n\n            label_cols = [col for _, col in test_asos_data_info_list[0]['hour_col_pairs']]\n            for col in label_cols:\n                indices = [i for i, data_dict in enumerate(test_asos_dataset.data_info_list[0]['data_dict_list']) \n                          if data_dict['label_col'] == col]\n\n                pred_vec_selected = pred_vecs[indices]\n                labels_selected = labels[indices]\n                results = calc_measure_valid(labels_selected, pred_vec_selected, cutoff=cutoff)\n\n                results_dict[cutoff_str]['asos'].setdefault(col, {}).setdefault('csi', []).append(results[0])\n                results_dict[cutoff_str]['asos'][col].setdefault('acc', []).append(results[1])\n                results_dict[cutoff_str]['asos'][col].setdefault('auroc', []).append(results[2])\n\n                # Land\n                pred_vec_land_selected = pred_vecs_land[indices]\n                labels_land_selected = labels_land[indices]\n                results_land = calc_measure_valid(labels_land_selected, pred_vec_land_selected, cutoff=cutoff)\n                results_dict[cutoff_str]['asos_land'].setdefault(col, {}).setdefault('csi', []).append(results_land[0])\n\n                # Coast\n                pred_vec_coast_selected = pred_vecs_coast[indices]\n                labels_coast_selected = labels_coast[indices]\n                results_coast = calc_measure_valid(labels_coast_selected, pred_vec_coast_selected, cutoff=cutoff)\n                results_dict[cutoff_str]['asos_coast'].setdefault(col, {}).setdefault('csi', []).append(results_coast[0])\n\n                print(f\"  {col}: CSI={results[0]:.4f}, Land={results_land[0]:.4f}, Coast={results_coast[0]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 집계\n",
    "all_results_rows = []\n",
    "\n",
    "for cutoff_str, type_dict_for_thr in results_dict.items():\n",
    "    for data_type, type_dict in type_dict_for_thr.items():\n",
    "        if not type_dict:\n",
    "            continue\n",
    "\n",
    "        csi_mean_list = []\n",
    "\n",
    "        for label_col, metrics_dict in type_dict.items():\n",
    "            if not metrics_dict.get('csi'):\n",
    "                continue\n",
    "\n",
    "            csi_mean = np.mean(metrics_dict['csi'])\n",
    "            csi_mean_list.append(csi_mean)\n",
    "\n",
    "            all_results_rows.append({\n",
    "                'type': data_type,\n",
    "                'threshold': cutoff_str,\n",
    "                'label': label_col,\n",
    "                'csi': f'{csi_mean:.4f}',\n",
    "            })\n",
    "\n",
    "        if csi_mean_list:\n",
    "            all_results_rows.append({\n",
    "                'type': data_type,\n",
    "                'threshold': cutoff_str,\n",
    "                'label': 'mean',\n",
    "                'csi': f'{np.mean(csi_mean_list):.4f}',\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(all_results_rows)\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "output_csv_path = f'{output_path}/final_results_tau.csv'\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nSaved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}