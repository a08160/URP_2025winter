{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Temporal Attention Unit (TAU) for Frost Prediction\n",
    "\n",
    "**Paper**: \"Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning\" (CVPR 2023)\n",
    "\n",
    "논문 구조 그대로 구현:\n",
    "1. Spatial Encoder: 단순 2D CNN\n",
    "2. Temporal Module: TAU 블록 스택\n",
    "   - Intra-frame Statical Attention (SA)\n",
    "   - Inter-frame Dynamical Attention (DA)\n",
    "3. Spatial Decoder: 단순 2D CNN with skip connection\n",
    "4. Loss: MSE + α * DDR (Differential Divergence Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import netCDF4 as nc\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *\n",
    "from utils.gk2a_dataset import GK2ADataset\n",
    "from utils.projection import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.frost_tau import FrostTAU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 1. 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOS weight: 1.00, AAFOS weight: 0.00\n",
      "Output path: results/asos_16ch_time[-18, -15, -12]_2km_tau_ws1_stride1\n"
     ]
    }
   ],
   "source": [
    "# ====== 실험 설정 ======\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "# 데이터 설정\n",
    "ASOS = True\n",
    "AAFOS = False\n",
    "\n",
    "channels = '16ch'\n",
    "time_range_list = [[-18, -15, -12], [-21, -18, -15, -12], [-24, -21, -18, -15, -12], [-27, -24, -21, -18, -15, -12], [-30, -27, -24, -21, -18, -15, -12]]\n",
    "time_range = time_range_list[0]  # 기본값 설정 (학습 루프에서 덮어씀)\n",
    "resolution = '2km'\n",
    "postfix = 'tau'\n",
    "\n",
    "window_size = 1\n",
    "window_stride = 1\n",
    "\n",
    "# ASOS/AAFOS 가중치\n",
    "asos_aafos_ratio = 5.0\n",
    "asos_weight = asos_aafos_ratio / (asos_aafos_ratio + 1.0 * AAFOS) if ASOS else 0.0\n",
    "aafos_weight = 1.0 / (asos_aafos_ratio * ASOS + 1.0) if AAFOS else 0.0\n",
    "print(f\"ASOS weight: {asos_weight:.2f}, AAFOS weight: {aafos_weight:.2f}\")\n",
    "\n",
    "# 채널 설정\n",
    "channels_name = ['vi004','vi005','vi006','vi008','nr013','nr016','sw038','wv063','wv069','wv073','ir087','ir096','ir105','ir112','ir123','ir133']\n",
    "channels_calib = channels_name.copy()\n",
    "\n",
    "channels_mean = [1.1912e-01, 1.1464e-01, 1.0734e-01, 1.2504e-01, 5.4983e-02, 9.0381e-02,\n",
    "            2.7813e+02, 2.3720e+02, 2.4464e+02, 2.5130e+02, 2.6948e+02, 2.4890e+02,\n",
    "            2.7121e+02, 2.7071e+02, 2.6886e+02, 2.5737e+02]\n",
    "channels_std = [0.1306,  0.1303,  0.1306,  0.1501,  0.0268,  0.0838, 15.8211,  6.1468,\n",
    "            7.8054,  9.3251, 16.4265,  9.6150, 17.2518, 17.6064, 17.0090, 12.5026]\n",
    "\n",
    "# output_path 설정\n",
    "output_path = \"results/\"\n",
    "output_path += 'asos_' if ASOS else ''\n",
    "output_path += 'aafos_' if AAFOS else ''\n",
    "output_path += channels + '_'\n",
    "output_path += 'time' + str(time_range) + '_'\n",
    "output_path += resolution\n",
    "output_path += ('_' + postfix) if postfix else ''\n",
    "output_path += f'_ws{window_size}_stride{window_stride}'\n",
    "print(f\"Output path: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "data-info",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len: 3\n",
      "total_channels: 19\n",
      "image_size: 192\n",
      "\n",
      "Window config: size=1, stride=1\n",
      "Number of windows: 3\n",
      "Head input channels: 57\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정보\n",
    "train_data_info_list = [{\n",
    "    'label_type': 'asos',\n",
    "    'start_date_str': '20200101',\n",
    "    'end_date_str': '20230630',\n",
    "    'hour_col_pairs': [(6,'AM')],\n",
    "    'label_keys': ['93','108','112','119','131','133','136','143','146','156','177','102','104','115','138','152','155','159','165','168','169','184','189']\n",
    "}] if ASOS else None\n",
    "\n",
    "test_asos_data_info_list = [{\n",
    "    'label_type': 'asos',\n",
    "    'start_date_str': '20230701',\n",
    "    'end_date_str': '20240630',\n",
    "    'hour_col_pairs': [(6,'AM')],\n",
    "    'label_keys': ['93','108','112','119','131','133','136','143','146','156','177','102','104','115','138','152','155','159','165','168','169','184','189']\n",
    "}] if ASOS else None\n",
    "\n",
    "# 이미지 설정\n",
    "origin_size = 900 if resolution == '2km' else 1800\n",
    "image_size = 192\n",
    "patch_size = 192\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/home/dm4/repo/data/kma_data/date_kst_URP'\n",
    "lat_lon_path = 'assets/gk2a_ami_ko010lc_latlon.nc'\n",
    "\n",
    "misc_channels = {\n",
    "    'elevation':'elevation_1km_3600.npy',\n",
    "    'vegetation':'vegetation_1km_3600.npy',\n",
    "    'watermap':'watermap_1km_avg_3600.npy'\n",
    "}\n",
    "\n",
    "# 학습 설정\n",
    "batch_size = 16\n",
    "num_workers = 8\n",
    "epochs = 25\n",
    "lr = 1e-3\n",
    "decay = [10, 20]\n",
    "lr_decay = 0.1\n",
    "weight_decay = 1e-5\n",
    "threshold = [0.25]\n",
    "\n",
    "# 관측소 좌표\n",
    "asos_x_base, asos_y_base, asos_image_size = get_crop_base(image_size, label_type='asos')\n",
    "seq_len = len(time_range)\n",
    "total_channels = len(channels_name) + len(misc_channels.keys())\n",
    "\n",
    "# 윈도우 설정 출력\n",
    "actual_window_size = window_size if window_size is not None else seq_len\n",
    "n_windows = (seq_len - actual_window_size) // window_stride + 1\n",
    "\n",
    "print(f\"seq_len: {seq_len}\")\n",
    "print(f\"total_channels: {total_channels}\")\n",
    "print(f\"image_size: {image_size}\")\n",
    "print(f\"\\nWindow config: size={actual_window_size}, stride={window_stride}\")\n",
    "print(f\"Number of windows: {n_windows}\")\n",
    "print(f\"Head input channels: {n_windows * actual_window_size * total_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "station-map",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOS stations: 23\n",
      "  - Land: 11\n",
      "  - Coast: 12\n"
     ]
    }
   ],
   "source": [
    "# 관측소 좌표\n",
    "asos_map_dict = get_station_map(image_size, label_type='asos', origin_size=origin_size)\n",
    "\n",
    "asos_land_keys = list(ASOS_LAND_COORD.keys())\n",
    "asos_coast_keys = list(ASOS_COAST_COORD.keys())\n",
    "asos_land_map = {k: v for k, v in asos_map_dict.items() if k in asos_land_keys}\n",
    "asos_coast_map = {k: v for k, v in asos_map_dict.items() if k in asos_coast_keys}\n",
    "\n",
    "print(f\"ASOS stations: {len(asos_map_dict)}\")\n",
    "print(f\"  - Land: {len(asos_land_map)}\")\n",
    "print(f\"  - Coast: {len(asos_coast_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "misc-images",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISC images shape: torch.Size([3, 192, 192])\n"
     ]
    }
   ],
   "source": [
    "# Misc 이미지 로드\n",
    "misc_images = []\n",
    "for misc_channel, misc_path in misc_channels.items():\n",
    "    misc_image = np.load(f'assets/misc_channels/{misc_path}', allow_pickle=True)\n",
    "    misc_image = process_misc_image(misc_image, image_size, interpolation='cubic')\n",
    "    misc_images.append(misc_image)\n",
    "\n",
    "misc_images = np.stack(misc_images, axis=0)\n",
    "misc_images = torch.tensor(misc_images, dtype=torch.float32)\n",
    "print(f\"MISC images shape: {misc_images.shape}\")\n",
    "\n",
    "# Normalize\n",
    "misc_mean = misc_images.mean(dim=[1,2], keepdim=True)\n",
    "misc_std = misc_images.std(dim=[1,2], keepdim=True)\n",
    "\n",
    "total_mean = channels_mean + misc_mean.squeeze().tolist()\n",
    "total_std = channels_std + misc_std.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "patch-candidates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOS patch candidates: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Patch candidates (192x192에서는 전체 이미지 사용)\n",
    "asos_patch_candidate = np.zeros([image_size, image_size], dtype=np.uint8)\n",
    "for x, y in asos_map_dict.values():\n",
    "    y_min = np.clip(y - 3*patch_size//4, 0, image_size - patch_size+1)\n",
    "    y_max = np.clip(y - patch_size//4, 0, image_size - patch_size+1)\n",
    "    x_min = np.clip(x - 3*patch_size//4, 0, image_size - patch_size+1)\n",
    "    x_max = np.clip(x - patch_size//4, 0, image_size - patch_size+1)\n",
    "    asos_patch_candidate[y_min:y_max, x_min:x_max] = 1\n",
    "\n",
    "asos_patch_candidate = np.argwhere(asos_patch_candidate == 1)[:, [1, 0]]\n",
    "patch_candidates = {'asos': asos_patch_candidate}\n",
    "print(f\"ASOS patch candidates: {asos_patch_candidate.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dataloader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:   1%|▌                                          | 16/1277 [00:00<00:08, 154.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20200101 AM skipped, 2019-12-31 12:00:00 not in date_table\n",
      "  - 20200104 AM skipped, 2020-01-03 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:  51%|█████████████████████▍                    | 651/1277 [00:02<00:01, 432.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20211003 AM skipped, 2021-10-02 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|█████████████████████████████████████████| 1277/1277 [00:05<00:00, 246.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 1274 image-label pairs prepared\n",
      "  - train_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 1274\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|███████████████████████████████████████████| 366/366 [00:01<00:00, 248.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 366 image-label pairs prepared\n",
      "  - test_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 366\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "class SequenceNormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32)\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        if tensor.dim() == 4:  # (T, C, H, W)\n",
    "            mean = self.mean.view(1, -1, 1, 1)\n",
    "            std = self.std.view(1, -1, 1, 1)\n",
    "        else:  # (C, H, W)\n",
    "            mean = self.mean.view(-1, 1, 1)\n",
    "            std = self.std.view(-1, 1, 1)\n",
    "        return (tensor - mean) / std\n",
    "\n",
    "transform = SequenceNormalize(mean=total_mean, std=total_std)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = GK2ADataset(\n",
    "    data_path=data_path, output_path=output_path, data_info_list=train_data_info_list,\n",
    "    channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "    image_size=image_size, misc_images=misc_images,\n",
    "    patch_size=patch_size, patch_candidates=patch_candidates,\n",
    "    transform=transform, train=True\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "if ASOS:\n",
    "    test_asos_dataset = GK2ADataset(\n",
    "        data_path=data_path, output_path=output_path, data_info_list=test_asos_data_info_list,\n",
    "        channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "        image_size=image_size, misc_images=misc_images,\n",
    "        patch_size=patch_size, patch_candidates=None,\n",
    "        transform=transform, train=False\n",
    "    )\n",
    "    test_asos_dataloader = DataLoader(test_asos_dataset, batch_size=batch_size//2, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. TAU 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "model-init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window config: size=1, stride=1\n",
      "Number of windows: 3\n",
      "Total parameters: 1,511,130\n",
      "Trainable parameters: 1,511,130\n"
     ]
    }
   ],
   "source": [
    "# TAU 모델 설정\n",
    "model = FrostTAU(\n",
    "    seq_len=seq_len,\n",
    "    in_channels=total_channels,\n",
    "    img_size=image_size,\n",
    "    out_channels=1,\n",
    "    hid_S=64,        # Encoder/Decoder hidden channels\n",
    "    N_S=4,           # Encoder/Decoder layers\n",
    "    N_T=8,           # TAU blocks\n",
    "    kernel_size=21,  # TAU attention kernel size\n",
    "    mlp_ratio=4.0,\n",
    "    drop=0.0,\n",
    "    drop_path=0.1,\n",
    "    # Window parameters\n",
    "    window_size=window_size,\n",
    "    window_stride=window_stride,\n",
    ").cuda()\n",
    "\n",
    "# 윈도우 설정 확인\n",
    "print(f\"Window config: size={model.window_size}, stride={model.window_stride}\")\n",
    "print(f\"Number of windows: {model.n_windows}\")\n",
    "\n",
    "# Parameter count\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {n_params:,}\")\n",
    "print(f\"Trainable parameters: {n_trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "model-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrostTAU(\n",
       "  (encoder): Encoder(\n",
       "    (enc): Sequential(\n",
       "      (0): ConvSC(\n",
       "        (conv): Conv2d(19, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvSC(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvSC(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvSC(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal): TemporalModule(\n",
       "    (blocks): ModuleList(\n",
       "      (0): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "      )\n",
       "      (2): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "      )\n",
       "      (3): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "      )\n",
       "      (4): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "      )\n",
       "      (5): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "      )\n",
       "      (6): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "      )\n",
       "      (7): TAUBlock(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (statical_attn): IntraFrameStaticalAttention(\n",
       "          (dw_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(10, 10), groups=64)\n",
       "          (dw_d_conv): Conv2d(64, 64, kernel_size=(21, 21), stride=(1, 1), padding=(30, 30), dilation=(3, 3), groups=64)\n",
       "          (conv_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dynamical_attn): InterFrameDynamicalAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dec): Sequential(\n",
       "      (0): ConvSC(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): PixelShuffle(upscale_factor=2)\n",
       "        )\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvSC(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): PixelShuffle(upscale_factor=2)\n",
       "        )\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvSC(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): PixelShuffle(upscale_factor=2)\n",
       "        )\n",
       "        (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dec_out): ConvSC(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (readout): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(57, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(38, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(19, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 4. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def calc_measure_valid(Y_test, Y_test_hat, cutoff=0.5):\n",
    "    Y_test = Y_test.ravel()\n",
    "    Y_test_hat = Y_test_hat.ravel()\n",
    "    \n",
    "    Y_valid = (~np.isnan(Y_test))\n",
    "    Y_test = Y_test[Y_valid]\n",
    "    Y_test_hat = Y_test_hat[Y_valid]\n",
    "\n",
    "    cfmat = confusion_matrix(Y_test, Y_test_hat > cutoff, labels=[0,1])\n",
    "    acc = np.trace(cfmat) / np.sum(cfmat)\n",
    "    csi = cfmat[1,1] / (np.sum(cfmat) - cfmat[0,0] + 1e-8)\n",
    "    \n",
    "    try:\n",
    "        auroc = roc_auc_score(Y_test, Y_test_hat)\n",
    "    except:\n",
    "        auroc = 0.0\n",
    "\n",
    "    return csi, acc, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "train-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, images, labels, coords, map_dict, cls_idx=0, lambda_tau=0.1):\n",
    "    \"\"\"TAU 학습 스텝 (Sliding Window 지원)\"\"\"\n",
    "    images = images.cuda(non_blocking=True)\n",
    "    labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "    y_target = images.clone()\n",
    "    pred_map, loss_dict = model(images, y_target)\n",
    "    pred_map = pred_map[:, cls_idx]\n",
    "\n",
    "    pred_vec = torch.zeros_like(labels)\n",
    "\n",
    "    for b, (px, py) in enumerate(coords):\n",
    "        for i, (x, y) in enumerate(map_dict.values()):\n",
    "            if px <= x < px + patch_size and py <= y < py + patch_size:\n",
    "                pred_vec[b, i] = pred_map[b, y - py, x - px]\n",
    "            else:\n",
    "                pred_vec[b, i] = labels[b, i]\n",
    "\n",
    "    labels_valid = (~torch.isnan(labels)).float()\n",
    "    labels = torch.nan_to_num(labels, 0.0)\n",
    "\n",
    "    # Focal loss\n",
    "    loss_focal_raw = sigmoid_focal_loss(pred_vec, labels, alpha=-1, gamma=2, reduction='none')\n",
    "    loss_focal = (loss_focal_raw * labels_valid).sum() / labels_valid.sum().clamp(min=1.0)\n",
    "\n",
    "    # Non-frost loss\n",
    "    valid_any_batch = (labels_valid.sum() > 0)\n",
    "    all_zero_batch = ((labels * labels_valid).sum() == 0)\n",
    "\n",
    "    if not (valid_any_batch and all_zero_batch):\n",
    "        loss_non_frost = torch.tensor(0.0, device=labels.device)\n",
    "    else:\n",
    "        loss_non_frost = binary_cross_entropy_with_logits(\n",
    "            pred_map, torch.zeros_like(pred_map), reduction='mean'\n",
    "        )\n",
    "\n",
    "    # CSI loss\n",
    "    prob = torch.sigmoid(pred_vec)\n",
    "    tp = torch.sum(prob * labels * labels_valid, dim=0)\n",
    "    fn = torch.sum((1 - prob) * labels * labels_valid, dim=0)\n",
    "    fp = torch.sum(prob * (1 - labels) * labels_valid, dim=0)\n",
    "    loss_csi = torch.mean(-torch.log(tp + 1e-10) + torch.log(tp + fn + fp + 1e-10))\n",
    "\n",
    "    # Total loss\n",
    "    loss_cls = loss_focal + loss_non_frost + loss_csi\n",
    "    \n",
    "    # TAU loss (MSE + DDR) - DDR은 window_size > 1일 때만 계산됨\n",
    "    loss_mse = loss_dict['loss_mse']\n",
    "    loss_ddr = loss_dict['loss_ddr']\n",
    "    loss_tau = loss_mse + loss_ddr\n",
    "    total_loss = loss_cls + lambda_tau * loss_tau\n",
    "\n",
    "    return total_loss, {\n",
    "        'cls': loss_cls.item(),\n",
    "        'mse': loss_mse.item() if torch.is_tensor(loss_mse) else loss_mse,\n",
    "        'ddr': loss_ddr.item() if torch.is_tensor(loss_ddr) else loss_ddr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "training-loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16\n",
      "Accumulation steps: 4\n",
      "Effective batch size: 64\n",
      "Window config: size=1, stride=1\n",
      "\n",
      "============================================================\n",
      "Running experiment with time_range=[-18, -15, -12]\n",
      "============================================================\n",
      "\n",
      "Output path: results/asos_16ch_time[-18, -15, -12]_2km_tau_ws1_stride1\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:   1%|▌                                          | 16/1277 [00:00<00:08, 155.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20200101 AM skipped, 2019-12-31 12:00:00 not in date_table\n",
      "  - 20200104 AM skipped, 2020-01-03 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos:  51%|█████████████████████▍                    | 652/1277 [00:02<00:01, 432.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 20211003 AM skipped, 2021-10-02 12:00:00 not in date_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|█████████████████████████████████████████| 1277/1277 [00:05<00:00, 246.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 1274 image-label pairs prepared\n",
      "  - train_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 1274\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|███████████████████████████████████████████| 366/366 [00:01<00:00, 248.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 366 image-label pairs prepared\n",
      "  - test_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 366\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "Seed 0 already done. Skipping...\n",
      "Seed 1 already done. Skipping...\n",
      "Seed 2 already done. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "lambda_tau = 0.1\n",
    "accumulation_steps = 4\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Accumulation steps: {accumulation_steps}\")\n",
    "print(f\"Effective batch size: {batch_size * accumulation_steps}\")\n",
    "print(f\"Window config: size={window_size}, stride={window_stride}\")\n",
    "\n",
    "for time_range in time_range_list:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running experiment with time_range={time_range}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    seq_len = len(time_range)\n",
    "    \n",
    "    # output_path 설정\n",
    "    output_path = \"results/\"\n",
    "    output_path += 'asos_' if ASOS else ''\n",
    "    output_path += 'aafos_' if AAFOS else ''\n",
    "    output_path += channels + '_'\n",
    "    output_path += 'time' + str(time_range) + '_'\n",
    "    output_path += resolution\n",
    "    output_path += ('_' + postfix) if postfix else ''\n",
    "    output_path += f'_ws{window_size}_stride{window_stride}'\n",
    "    print(f\"Output path: {output_path}\")\n",
    "    \n",
    "    # Dataset 생성\n",
    "    train_dataset = GK2ADataset(\n",
    "        data_path=data_path, output_path=output_path, data_info_list=train_data_info_list,\n",
    "        channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "        image_size=image_size, misc_images=misc_images,\n",
    "        patch_size=patch_size, patch_candidates=patch_candidates,\n",
    "        transform=transform, train=True\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "\n",
    "    test_asos_dataset = GK2ADataset(\n",
    "        data_path=data_path, output_path=output_path, data_info_list=test_asos_data_info_list,\n",
    "        channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "        image_size=image_size, misc_images=misc_images,\n",
    "        patch_size=patch_size, patch_candidates=None,\n",
    "        transform=transform, train=False\n",
    "    )\n",
    "    test_asos_dataloader = DataLoader(test_asos_dataset, batch_size=batch_size//2, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "    for seed in seeds:\n",
    "        if os.path.exists(f'{output_path}/{seed}/ckpt.pt'):\n",
    "            print(f'Seed {seed} already done. Skipping...')\n",
    "            continue\n",
    "\n",
    "        set_seed(seed)\n",
    "        os.makedirs(f'{output_path}/{seed}', exist_ok=True)\n",
    "\n",
    "        model = FrostTAU(\n",
    "            seq_len=seq_len,\n",
    "            in_channels=total_channels,\n",
    "            img_size=image_size,\n",
    "            out_channels=1,\n",
    "            hid_S=64,\n",
    "            N_S=4,\n",
    "            N_T=8,\n",
    "            kernel_size=21,\n",
    "            mlp_ratio=4.0,\n",
    "            drop=0.0,\n",
    "            drop_path=0.1,\n",
    "            window_size=window_size,\n",
    "            window_stride=window_stride,\n",
    "        ).cuda()\n",
    "\n",
    "        print(f\"Model window_size={model.window_size}, n_windows={model.n_windows}\")\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay, gamma=lr_decay)\n",
    "\n",
    "        results = {\n",
    "            'loss': {'asos': [], 'total': []},\n",
    "            'csi': {'asos': {}},\n",
    "            'acc': {'asos': {}},\n",
    "            'auroc': {'asos': []},\n",
    "            'best_asos': {},\n",
    "        }\n",
    "\n",
    "        for cutoff_str in threshold:\n",
    "            cutoff_str = str(cutoff_str)\n",
    "            results['csi']['asos'][cutoff_str] = []\n",
    "            results['acc']['asos'][cutoff_str] = []\n",
    "            results['best_asos'][cutoff_str] = {'csi': 0.0, 'epoch': -1, 'model': None}\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "\n",
    "            total_loss = 0.0\n",
    "            total_loss_cls = 0.0\n",
    "            total_loss_mse = 0.0\n",
    "            total_loss_ddr = 0.0\n",
    "\n",
    "            train_dataset.sync_dataset_length()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch}\")):\n",
    "                images, label, coords = batch[0]\n",
    "                loss, loss_breakdown = train_step(\n",
    "                    model, images, label, coords, asos_map_dict,\n",
    "                    cls_idx=0, lambda_tau=lambda_tau\n",
    "                )\n",
    "\n",
    "                loss = loss / accumulation_steps\n",
    "                loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                total_loss += float(loss.item()) * accumulation_steps\n",
    "                total_loss_cls += loss_breakdown['cls']\n",
    "                total_loss_mse += loss_breakdown['mse']\n",
    "                total_loss_ddr += loss_breakdown['ddr']\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            n_batches = len(train_dataloader)\n",
    "            total_loss /= n_batches\n",
    "            total_loss_cls /= n_batches\n",
    "            total_loss_mse /= n_batches\n",
    "            total_loss_ddr /= n_batches\n",
    "\n",
    "            print(f\"Epoch {epoch} - Total: {total_loss:.4f}\")\n",
    "            print(f\"  L_cls: {total_loss_cls:.4f}, L_mse: {total_loss_mse:.4f}, L_ddr: {total_loss_ddr:.4f}\")\n",
    "\n",
    "            results['loss']['total'].append(total_loss)\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred_vecs = []\n",
    "                labels_list = []\n",
    "                pred_vecs_land = []\n",
    "                labels_land = []\n",
    "                pred_vecs_coast = []\n",
    "                labels_coast = []\n",
    "\n",
    "                for batch in test_asos_dataloader:\n",
    "                    images, label, coords = batch[0]\n",
    "                    images = images.cuda(non_blocking=True)\n",
    "\n",
    "                    pred_map = model(images)[:, 0]\n",
    "\n",
    "                    for b, (px, py) in enumerate(coords):\n",
    "                        pred_vec = []\n",
    "                        label_vec = []\n",
    "                        pred_vec_land = []\n",
    "                        label_land = []\n",
    "                        pred_vec_coast = []\n",
    "                        label_coast = []\n",
    "\n",
    "                        for i, (key, (x, y)) in enumerate(asos_map_dict.items()):\n",
    "                            if px <= x < px + patch_size and py <= y < py + patch_size:\n",
    "                                pred_val = pred_map[b, y - py, x - px].item()\n",
    "                                label_val = label[b, i].item()\n",
    "\n",
    "                                pred_vec.append(pred_val)\n",
    "                                label_vec.append(label_val)\n",
    "\n",
    "                                if key in asos_land_keys:\n",
    "                                    pred_vec_land.append(pred_val)\n",
    "                                    label_land.append(label_val)\n",
    "                                elif key in asos_coast_keys:\n",
    "                                    pred_vec_coast.append(pred_val)\n",
    "                                    label_coast.append(label_val)\n",
    "\n",
    "                        if pred_vec:\n",
    "                            pred_vecs.append(pred_vec)\n",
    "                            labels_list.append(label_vec)\n",
    "                        if pred_vec_land:\n",
    "                            pred_vecs_land.append(pred_vec_land)\n",
    "                            labels_land.append(label_land)\n",
    "                        if pred_vec_coast:\n",
    "                            pred_vecs_coast.append(pred_vec_coast)\n",
    "                            labels_coast.append(label_coast)\n",
    "\n",
    "                pred_vecs = np.array([p for pv in pred_vecs for p in pv])\n",
    "                labels_list = np.array([l for lv in labels_list for l in lv])\n",
    "                pred_vecs_land = np.array([p for pv in pred_vecs_land for p in pv])\n",
    "                labels_land = np.array([l for lv in labels_land for l in lv])\n",
    "                pred_vecs_coast = np.array([p for pv in pred_vecs_coast for p in pv])\n",
    "                labels_coast = np.array([l for lv in labels_coast for l in lv])\n",
    "\n",
    "                for cutoff in threshold:\n",
    "                    cutoff_str = str(cutoff)\n",
    "                    csi, acc, auroc = calc_measure_valid(labels_list, pred_vecs, cutoff=cutoff)\n",
    "                    results['csi']['asos'][cutoff_str].append(csi)\n",
    "                    results['acc']['asos'][cutoff_str].append(acc)\n",
    "\n",
    "                    csi_land, _, _ = calc_measure_valid(labels_land, pred_vecs_land, cutoff=cutoff)\n",
    "                    csi_coast, _, _ = calc_measure_valid(labels_coast, pred_vecs_coast, cutoff=cutoff)\n",
    "\n",
    "                    is_best = csi > results['best_asos'][cutoff_str]['csi']\n",
    "                    results['auroc']['asos'].append(auroc)\n",
    "\n",
    "                    if is_best:\n",
    "                        results['best_asos'][cutoff_str]['csi'] = csi\n",
    "                        results['best_asos'][cutoff_str]['epoch'] = epoch\n",
    "                        results['best_asos'][cutoff_str]['model'] = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                    print(f\"  ASOS (T={cutoff}): CSI {csi:.4f}, AUROC {auroc:.4f} {'*' if is_best else ''}\")\n",
    "                    print(f\"    Land: {csi_land:.4f}, Coast: {csi_coast:.4f}\")\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'results': results,\n",
    "                'window_size': window_size,\n",
    "                'window_stride': window_stride,\n",
    "            }, f'{output_path}/{seed}/resume.pt')\n",
    "\n",
    "        for cutoff_str in threshold:\n",
    "            cutoff_str = str(cutoff_str)\n",
    "            if results['best_asos'][cutoff_str]['model'] is not None:\n",
    "                torch.save({\n",
    "                    'model': results['best_asos'][cutoff_str]['model'],\n",
    "                    'epoch': results['best_asos'][cutoff_str]['epoch'],\n",
    "                    'csi': results['best_asos'][cutoff_str]['csi'],\n",
    "                    'window_size': window_size,\n",
    "                    'window_stride': window_stride,\n",
    "                }, f'{output_path}/{seed}/ckpt.pt')\n",
    "                print(f\"Seed {seed} - Best CSI: {results['best_asos'][cutoff_str]['csi']:.4f}\")\n",
    "\n",
    "        if os.path.exists(f'{output_path}/{seed}/resume.pt'):\n",
    "            os.remove(f'{output_path}/{seed}/resume.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running experiment with time_range=[-18, -15, -12]\n",
      "============================================================\n",
      "\n",
      "Output path: results/asos_16ch_time[-18, -15, -12]_2km_tau_ws1_stride1\n",
      "== Preparing asos...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing asos: 100%|███████████████████████████████████████████| 366/366 [00:01<00:00, 247.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Total 366 image-label pairs prepared\n",
      "  - test_asos_image_label_list.yaml saved\n",
      "\n",
      "== asos dataset length synced to 366\n",
      "GK2A Dataset initialized\n",
      "\n",
      "\n",
      "--- Seed 0: epoch 17, CSI 0.5117 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Seed 0: 100%|██████████| 46/46 [00:11<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AM: CSI=0.5204, Land=0.5817, Coast=0.2657\n",
      "--- Seed 1: epoch 4, CSI 0.5266 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Seed 1: 100%|██████████| 46/46 [00:11<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AM: CSI=0.4894, Land=0.5439, Coast=0.2715\n",
      "--- Seed 2: epoch 18, CSI 0.5238 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Seed 2: 100%|██████████| 46/46 [00:11<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AM: CSI=0.5027, Land=0.5543, Coast=0.2837\n",
      "\n",
      "=== Final Results ===\n",
      "      type threshold label    csi    acc  auroc\n",
      "      asos      0.25    AM 0.5042 0.9138 0.9099\n",
      "      asos      0.25  mean 0.5042 0.9138 0.9099\n",
      " asos_land      0.25    AM 0.5600 0.8713 0.9522\n",
      " asos_land      0.25  mean 0.5600 0.8713 0.9522\n",
      "asos_coast      0.25    AM 0.2736 0.9529 0.8276\n",
      "asos_coast      0.25  mean 0.2736 0.9529 0.8276\n",
      "\n",
      "Saved to results/asos_16ch_time[-18, -15, -12]_2km_tau_ws1_stride1/final_results_tau.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_LAND = 11\n",
    "N_COAST = 12\n",
    "\n",
    "for time_range in time_range_list:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running experiment with time_range={time_range}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    seq_len = len(time_range)\n",
    "    \n",
    "    # output_path 설정\n",
    "    output_path = \"results/\"\n",
    "    output_path += 'asos_' if ASOS else ''\n",
    "    output_path += 'aafos_' if AAFOS else ''\n",
    "    output_path += channels + '_'\n",
    "    output_path += 'time' + str(time_range) + '_'\n",
    "    output_path += resolution\n",
    "    output_path += ('_' + postfix) if postfix else ''\n",
    "    output_path += f'_ws{window_size}_stride{window_stride}'\n",
    "    print(f\"Output path: {output_path}\")\n",
    "    \n",
    "    # Test Dataset 생성\n",
    "    test_asos_dataset = GK2ADataset(\n",
    "        data_path=data_path, output_path=output_path, data_info_list=test_asos_data_info_list,\n",
    "        channels=channels, time_range=time_range, channels_calib=channels_calib,\n",
    "        image_size=image_size, misc_images=misc_images,\n",
    "        patch_size=patch_size, patch_candidates=None,\n",
    "        transform=transform, train=False\n",
    "    )\n",
    "    test_asos_dataloader = DataLoader(test_asos_dataset, batch_size=batch_size//2, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "    results_dict = {}\n",
    "    for cutoff in threshold:\n",
    "        results_dict[str(cutoff)] = {\n",
    "            'asos': {},\n",
    "            'asos_land': {},\n",
    "            'asos_coast': {},\n",
    "        }\n",
    "\n",
    "    for seed in seeds:\n",
    "        ckpt_path = f'{output_path}/{seed}/ckpt.pt'\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            print(f'Seed {seed} not found. Skipping...')\n",
    "            continue\n",
    "    \n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        print(f'--- Seed {seed}: epoch {ckpt[\"epoch\"]}, CSI {ckpt[\"csi\"]:.4f} ---')\n",
    "    \n",
    "        # 저장된 window 설정 로드 (없으면 기본값)\n",
    "        ckpt_window_size = ckpt.get('window_size', window_size)\n",
    "        ckpt_window_stride = ckpt.get('window_stride', window_stride)\n",
    "\n",
    "        model = FrostTAU(\n",
    "            seq_len=seq_len,\n",
    "            in_channels=total_channels,\n",
    "            img_size=image_size,\n",
    "            out_channels=1,\n",
    "            hid_S=64,\n",
    "            N_S=4,\n",
    "            N_T=8,\n",
    "            kernel_size=21,\n",
    "            mlp_ratio=4.0,\n",
    "            drop=0.0,\n",
    "            drop_path=0.1,\n",
    "            window_size=ckpt_window_size,\n",
    "            window_stride=ckpt_window_stride,\n",
    "        ).cuda()\n",
    "    \n",
    "        model.load_state_dict(ckpt['model'])\n",
    "        model.eval()\n",
    "    \n",
    "        for cutoff in threshold:\n",
    "            cutoff_str = str(cutoff)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                asos_pred_vec_list = []\n",
    "                asos_labels_list = []\n",
    "\n",
    "                for batch in tqdm(test_asos_dataloader, desc=f\"Eval Seed {seed}\"):\n",
    "                    images, label, coords = batch[0]\n",
    "                    images = images.cuda()\n",
    "\n",
    "                    pred_map = model(images)[:, 0]\n",
    "                    pred_map = torch.sigmoid(pred_map)\n",
    "\n",
    "                    pred_vec = []\n",
    "                    for x, y in asos_map_dict.values():\n",
    "                        if 0 <= y < pred_map.shape[1] and 0 <= x < pred_map.shape[2]:\n",
    "                            pred_vec.append(pred_map[:, y, x])\n",
    "                        else:\n",
    "                            pred_vec.append(torch.zeros(pred_map.shape[0], device=pred_map.device))\n",
    "                    pred_vec = torch.stack(pred_vec, dim=1)\n",
    "\n",
    "                    asos_pred_vec_list.append(pred_vec.cpu().numpy())\n",
    "                    asos_labels_list.append(label.numpy())\n",
    "\n",
    "                pred_vecs = np.concatenate(asos_pred_vec_list, axis=0)\n",
    "                labels = np.concatenate(asos_labels_list, axis=0)\n",
    "\n",
    "                pred_vecs_land = pred_vecs[:, :N_LAND]\n",
    "                pred_vecs_coast = pred_vecs[:, N_LAND:]\n",
    "                labels_land = labels[:, :N_LAND]\n",
    "                labels_coast = labels[:, N_LAND:]\n",
    "\n",
    "                label_cols = [col for _, col in test_asos_data_info_list[0]['hour_col_pairs']]\n",
    "                for col in label_cols:\n",
    "                    indices = [i for i, data_dict in enumerate(test_asos_dataset.data_info_list[0]['data_dict_list']) \n",
    "                              if data_dict['label_col'] == col]\n",
    "\n",
    "                    pred_vec_selected = pred_vecs[indices]\n",
    "                    labels_selected = labels[indices]\n",
    "                    results = calc_measure_valid(labels_selected, pred_vec_selected, cutoff=cutoff)\n",
    "\n",
    "                    results_dict[cutoff_str]['asos'].setdefault(col, {}).setdefault('csi', []).append(results[0])\n",
    "                    results_dict[cutoff_str]['asos'][col].setdefault('acc', []).append(results[1])\n",
    "                    results_dict[cutoff_str]['asos'][col].setdefault('auroc', []).append(results[2])\n",
    "    \n",
    "                    # Land\n",
    "                    pred_vec_land_selected = pred_vecs_land[indices]\n",
    "                    labels_land_selected = labels_land[indices]\n",
    "                    results_land = calc_measure_valid(labels_land_selected, pred_vec_land_selected, cutoff=cutoff)\n",
    "                    results_dict[cutoff_str]['asos_land'].setdefault(col, {}).setdefault('csi', []).append(results_land[0])\n",
    "                    results_dict[cutoff_str]['asos_land'][col].setdefault('acc', []).append(results_land[1])\n",
    "                    results_dict[cutoff_str]['asos_land'][col].setdefault('auroc', []).append(results_land[2])\n",
    "\n",
    "                    # Coast\n",
    "                    pred_vec_coast_selected = pred_vecs_coast[indices]\n",
    "                    labels_coast_selected = labels_coast[indices]\n",
    "                    results_coast = calc_measure_valid(labels_coast_selected, pred_vec_coast_selected, cutoff=cutoff)\n",
    "                    results_dict[cutoff_str]['asos_coast'].setdefault(col, {}).setdefault('csi', []).append(results_coast[0])\n",
    "                    results_dict[cutoff_str]['asos_coast'][col].setdefault('acc', []).append(results_coast[1])\n",
    "                    results_dict[cutoff_str]['asos_coast'][col].setdefault('auroc', []).append(results_coast[2])\n",
    "\n",
    "                    print(f\"  {col}: CSI={results[0]:.4f}, Land={results_land[0]:.4f}, Coast={results_coast[0]:.4f}\")\n",
    "\n",
    "    # 결과 집계 (모든 시드 평가 후 - 들여쓰기 수정됨)\n",
    "    all_results_rows = []\n",
    "\n",
    "    for cutoff_str, type_dict_for_thr in results_dict.items():\n",
    "        for data_type, type_dict in type_dict_for_thr.items():\n",
    "            if not type_dict:\n",
    "                continue\n",
    "\n",
    "            csi_mean_list = []\n",
    "            acc_mean_list = []\n",
    "            auroc_mean_list = []\n",
    "\n",
    "            for label_col, metrics_dict in type_dict.items():\n",
    "                if not metrics_dict.get('csi'):\n",
    "                    continue\n",
    "\n",
    "                csi_mean = np.mean(metrics_dict['csi'])\n",
    "                csi_mean_list.append(csi_mean)\n",
    "                \n",
    "                acc_mean = np.mean(metrics_dict['acc']) if metrics_dict.get('acc') else None\n",
    "                auroc_mean = np.mean(metrics_dict['auroc']) if metrics_dict.get('auroc') else None\n",
    "            \n",
    "                if acc_mean is not None:\n",
    "                    acc_mean_list.append(acc_mean)\n",
    "                if auroc_mean is not None:\n",
    "                    auroc_mean_list.append(auroc_mean)\n",
    "\n",
    "                row = {\n",
    "                    'type': data_type,\n",
    "                    'threshold': cutoff_str,\n",
    "                    'label': label_col,\n",
    "                    'csi': f'{csi_mean:.4f}',\n",
    "                }\n",
    "                if acc_mean is not None:\n",
    "                    row['acc'] = f'{acc_mean:.4f}'\n",
    "                if auroc_mean is not None:\n",
    "                    row['auroc'] = f'{auroc_mean:.4f}'\n",
    "            \n",
    "                all_results_rows.append(row)\n",
    "\n",
    "            if csi_mean_list:\n",
    "                row = {\n",
    "                    'type': data_type,\n",
    "                    'threshold': cutoff_str,\n",
    "                    'label': 'mean',\n",
    "                    'csi': f'{np.mean(csi_mean_list):.4f}',\n",
    "                }\n",
    "                if acc_mean_list:\n",
    "                    row['acc'] = f'{np.mean(acc_mean_list):.4f}'\n",
    "                if auroc_mean_list:\n",
    "                    row['auroc'] = f'{np.mean(auroc_mean_list):.4f}'\n",
    "            \n",
    "                all_results_rows.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(all_results_rows)\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    output_csv_path = f'{output_path}/final_results_tau.csv'\n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nSaved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
